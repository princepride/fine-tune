{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"are you tired today and you're losing your eyes?\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "fugu_translator = pipeline('translation', model='staka/fugumt-ja-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"are you tired today and you're losing your eyes?\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fugu_translator('今日 も 疲れ て 目 を 落とし て いる の ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"well then, massa, i'll give it to you.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fugu_translator('じゃあ , マッサ - ジ し て あげる .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MBartForConditionalGeneration, MBartTokenizer\n",
    ")\n",
    "\n",
    "tokenizer = MBartTokenizer.from_pretrained(\"ken11/mbart-ja-en\")\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"ken11/mbart-ja-en\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码是用于机器翻译任务的一个例子，它使用了一个预训练的模型将日语文本（\"こんにちは\"）翻译成英语。以下是代码的详细解释：\n",
    "\n",
    "1.inputs = tokenizer(\"こんにちは\", return_tensors=\"pt\")：这一行将日语文本 \"こんにちは\" 作为输入，并使用 tokenizer 对其进行编码。return_tensors=\"pt\" 表示返回的张量类型为 PyTorch 张量。\n",
    "\n",
    "2.translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id[\"en_XX\"], early_stopping=True, max_length=48)：这一行使用预训练的模型 (model) 对输入进行翻译。decoder_start_token_id 参数表示翻译目标语言的起始 token ID（在这个例子中，目标语言是英语）。early_stopping=True 表示当翻译过程满足某个停止条件时，会提前结束翻译。max_length=48 限制了翻译结果的最大长度。\n",
    "\n",
    "3.pred = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]：这一行将翻译后的 token 序列解码为英语文本。skip_special_tokens=True 表示在解码过程中跳过特殊 token（如起始、结束、填充等 token）。\n",
    "\n",
    "总结：这段代码使用了一个预训练的机器翻译模型，将日语文本 \"こんにちは\" 翻译成英语文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you tired today? are you losing your eye?\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"今日 も 疲れ て 目 を 落とし て いる の ?\", return_tensors=\"pt\")\n",
    "translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id[\"en_XX\"], early_stopping=True, max_length=48)\n",
    "pred = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well, then, i'll give you a masse.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"じゃあ , マッサ - ジ し て あげる .\", return_tensors=\"pt\")\n",
    "translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id[\"en_XX\"], early_stopping=True, max_length=48)\n",
    "pred = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
